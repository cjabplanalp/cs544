{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2d99a21-f94c-480a-b241-b28ed746b62d",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6459f52-a586-40c3-bea3-92ce42072c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://pages.cs.wisc.edu/~harter/cs639/data/hdma-wi-2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a695cd0-92cd-4951-b1b1-b7318f5e02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=1 -cp hdma-wi-2021.csv hdfs://main:9000/single.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55658445-bcf4-4d33-897d-59cb94c28b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=2 -cp hdma-wi-2021.csv hdfs://main:9000/double.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb721f0b-223f-4ae4-afa8-f8d03fbf235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.8 M  333.7 M  hdfs://main:9000/double.csv\n",
      "166.8 M  166.8 M  hdfs://main:9000/single.csv\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du -h hdfs://main:9000/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a232a803-5a86-4985-b1cf-b65e9416dc75",
   "metadata": {},
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0444d47f-b709-4e41-8202-7066b72c936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, math, io, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e587b74c-76fa-421c-b160-7e6c5f557871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! curl -i \"http://main:9870/webhdfs/v1/single.csv?op=OPEN&offset=0\"\n",
    "# resp = requests.get(\"http://main:9870/webhdfs/v1/single.csv?op=OPEN&offset=0\", allow_redirects=False)\n",
    "# resp.headers\n",
    "# resp.headers[\"Location\"]\n",
    "# new_resp = requests.get(resp.headers[\"Location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d217da48-f945-41ea-93c9-82ae8aee3194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://478292fd6023:9864/webhdfs/v1/single.csv': 85,\n",
       " 'http://e4fe85ff4375:9864/webhdfs/v1/single.csv': 82}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #1 MB = 1048576\n",
    "dummy_resp = requests.get(\"http://main:9870/webhdfs/v1/single.csv?op=GETFILESTATUS\", allow_redirects=False)\n",
    "block_size = math.ceil(dummy_resp.json()[\"FileStatus\"][\"length\"] / 1024 / 1024)\n",
    "\n",
    "urls = {}\n",
    "for i in range(block_size):\n",
    "    offset = 1048576 * i\n",
    "    resp = requests.get(f\"http://main:9870/webhdfs/v1/single.csv?op=OPEN&offset={offset}\", allow_redirects=False)\n",
    "    resp_url = resp.headers[\"Location\"]\n",
    "    \n",
    "    # use regex to grab the string before the \"?\" (as shown in the Part 2 specification)\n",
    "    url_edit = resp_url.split(\"?\")[0]\n",
    "    \n",
    "    #dict mapping w/ counts\n",
    "    if url_edit not in urls:\n",
    "        urls[url_edit] = 1\n",
    "    else:\n",
    "        urls[url_edit] += 1\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d995acd-29e1-4e3b-91b9-e17a56630f2a",
   "metadata": {},
   "source": [
    "# PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d74c2f-a6e3-4ef7-869c-77c510aa66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hdfsFile(io.RawIOBase):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.offset = 0\n",
    "        self.length = requests.get(f\"http://main:9870/webhdfs/v1/{self.path}?op=GETFILESTATUS\", allow_redirects=False).json()[\"FileStatus\"][\"length\"]\n",
    "\n",
    "    def readable(self):\n",
    "        return True\n",
    "\n",
    "    def readinto(self, b):\n",
    "        if self.offset < self.length:\n",
    "            temp_resp = requests.get(f\"http://main:9870/webhdfs/v1/{self.path}?op=OPEN&offset={self.offset}&length={len(b)}\", allow_redirects=False)\n",
    "            # print(temp_resp.status_code)\n",
    "            \n",
    "            # PART 4\n",
    "            if temp_resp.status_code != 307:\n",
    "                self.offset += 1024**2\n",
    "                b[:1] = bytes(\"\\n\", \"utf-8\")\n",
    "                return 1\n",
    "            \n",
    "            resp = requests.get(temp_resp.headers[\"Location\"])\n",
    "            text = bytes(resp.text, \"utf-8\")\n",
    "            b[:len(text)] = text\n",
    "            self.offset += len(b)\n",
    "            return len(text)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffc4584-f29d-4320-9333-fca51ad977de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from single.csv using 1MB buffer_size\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n",
      "Seconds: 14.653716802597046\n"
     ]
    }
   ],
   "source": [
    "single_family_count_1MB = 0\n",
    "multi_family_count_1MB = 0\n",
    "\n",
    "start = time.time()\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size =(1024**2)): # 1MB\n",
    "    line = str(line, \"utf-8\")\n",
    "    # print(line)\n",
    "    \n",
    "    if \"Single Family\" in line:\n",
    "        single_family_count_1MB += 1\n",
    "        \n",
    "    if \"Multifamily\" in line:\n",
    "        multi_family_count_1MB += 1\n",
    "        \n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Counts from single.csv using 1MB buffer_size\")\n",
    "print(\"Single Family:\", single_family_count_1MB)\n",
    "print(\"Multi Family:\", multi_family_count_1MB)\n",
    "print(\"Seconds:\", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d703136-c76f-4b97-88e8-84e16d7d3d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from single.csv using 2MB buffer_size\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n",
      "Seconds: 5.959940195083618\n"
     ]
    }
   ],
   "source": [
    "single_family_count_2MB = 0\n",
    "multi_family_count_2MB = 0\n",
    "\n",
    "start = time.time()\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size =(1000**2)*2): # 2MB\n",
    "    line = str(line, \"utf-8\")\n",
    "    # print(line)\n",
    "    \n",
    "    if \"Single Family\" in line:\n",
    "        single_family_count_2MB += 1\n",
    "        \n",
    "    if \"Multifamily\" in line:\n",
    "        multi_family_count_2MB += 1\n",
    "        \n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print(\"Counts from single.csv using 2MB buffer_size\")\n",
    "print(\"Single Family:\", single_family_count_2MB)\n",
    "print(\"Multi Family:\", multi_family_count_2MB)\n",
    "print(\"Seconds:\", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875c822-5db1-40b4-979a-e517f04d69d2",
   "metadata": {},
   "source": [
    "# PART 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c60b6897-d55d-41ef-b6f8-baf868151dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured Capacity: 51642105856 (48.10 GB)\n",
      "Present Capacity: 36001053820 (33.53 GB)\n",
      "DFS Remaining: 35472068608 (33.04 GB)\n",
      "DFS Used: 528985212 (504.48 MB)\n",
      "DFS Used%: 1.47%\n",
      "Replicated Blocks:\n",
      "\tUnder replicated blocks: 0\n",
      "\tBlocks with corrupt replicas: 0\n",
      "\tMissing blocks: 0\n",
      "\tMissing blocks (with replication factor 1): 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "Erasure Coded Block Groups: \n",
      "\tLow redundancy block groups: 0\n",
      "\tBlock groups with corrupt internal blocks: 0\n",
      "\tMissing block groups: 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (1):\n",
      "\n",
      "Name: 172.18.0.4:9866 (project-3-cam-worker-2.cs544net)\n",
      "Hostname: e4fe85ff4375\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 25821052928 (24.05 GB)\n",
      "DFS Used: 262822741 (250.65 MB)\n",
      "Non DFS Used: 7805433003 (7.27 GB)\n",
      "DFS Remaining: 17736019968 (16.52 GB)\n",
      "DFS Used%: 1.02%\n",
      "DFS Remaining%: 68.69%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 1\n",
      "Last contact: Sat Mar 18 22:07:16 GMT 2023\n",
      "Last Block Report: Sat Mar 18 22:01:25 GMT 2023\n",
      "Num of Blocks: 249\n",
      "\n",
      "\n",
      "Dead datanodes (1):\n",
      "\n",
      "Name: 172.18.0.3:9866 (172.18.0.3)\n",
      "Hostname: 478292fd6023\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 25821052928 (24.05 GB)\n",
      "DFS Used: 266162471 (253.83 MB)\n",
      "Non DFS Used: 7802064601 (7.27 GB)\n",
      "DFS Remaining: 17736048640 (16.52 GB)\n",
      "DFS Used%: 1.03%\n",
      "DFS Remaining%: 68.69%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 1\n",
      "Last contact: Sat Mar 18 22:05:37 GMT 2023\n",
      "Last Block Report: Sat Mar 18 22:01:25 GMT 2023\n",
      "Num of Blocks: 252\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -fs hdfs://main:9000/ -report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f7bb6a2-0ca0-4258-9de8-9ee8e6b90875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from double.csv\n",
      "Single Family: 444874\n",
      "Multi Family: 2493\n"
     ]
    }
   ],
   "source": [
    "double_single_family_count = 0\n",
    "double_multi_family_count = 0\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"double.csv\"), buffer_size =1048576): # 1MB\n",
    "    line = str(line, \"utf-8\")\n",
    "    # print(line)\n",
    "    \n",
    "    if \"Single Family\" in line:\n",
    "        double_single_family_count += 1\n",
    "        \n",
    "    if \"Multifamily\" in line:\n",
    "        double_multi_family_count += 1\n",
    "\n",
    "print(\"Counts from double.csv\")\n",
    "print(\"Single Family:\", double_single_family_count)\n",
    "print(\"Multi Family:\", double_multi_family_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc49c244-bd8b-4dc9-8e06-0917c711761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts from single.csv\n",
      "Single Family: 218589\n",
      "Multi Family: 993\n"
     ]
    }
   ],
   "source": [
    "single_single_family_count = 0\n",
    "single_multi_family_count = 0\n",
    "\n",
    "for line in io.BufferedReader(hdfsFile(\"single.csv\"), buffer_size =1048576): # 1MB\n",
    "    line = str(line, \"utf-8\")\n",
    "    # print(line)\n",
    "    \n",
    "    if \"Single Family\" in line:\n",
    "        single_single_family_count += 1\n",
    "        \n",
    "    if \"Multifamily\" in line:\n",
    "        single_multi_family_count += 1\n",
    "\n",
    "print(\"Counts from single.csv\")\n",
    "print(\"Single Family:\", single_single_family_count)\n",
    "print(\"Multi Family:\", single_multi_family_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
